{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting panderaNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pandera-0.19.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting multimethod<=1.10.0 (from pandera)\n",
      "  Downloading multimethod-1.10-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from pandera) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from pandera) (23.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from pandera) (2.2.2)\n",
      "Collecting pydantic (from pandera)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "     ---------------------------------------- 0.0/109.4 kB ? eta -:--:--\n",
      "     ---------- -------------------------- 30.7/109.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ---------- -------------------------- 30.7/109.4 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------------ ------------ 71.7/109.4 kB 491.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 109.4/109.4 kB 635.9 kB/s eta 0:00:00\n",
      "Collecting typeguard (from pandera)\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting typing-inspect>=0.6.0 (from pandera)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from pandera)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from pandas>=1.2.0->pandera) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from pandas>=1.2.0->pandera) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from pandas>=1.2.0->pandera) (2024.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.6.0->pandera)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting typing-extensions>=3.7.4 (from typing-inspect>=0.6.0->pandera)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->pandera)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic->pandera)\n",
      "  Downloading pydantic_core-2.18.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\'py-11'\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pandera) (1.16.0)\n",
      "Downloading pandera-0.19.3-py3-none-any.whl (251 kB)\n",
      "   ---------------------------------------- 0.0/251.9 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 112.6/251.9 kB ? eta -:--:--\n",
      "   ---------------------------------------  245.8/251.9 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 251.9/251.9 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading multimethod-1.10-py3-none-any.whl (9.9 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.0 kB ? eta -:--:--\n",
      "   ----------------------- --------------- 245.8/409.0 kB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 337.9/409.0 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.0/409.0 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.4/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: wrapt, typing-extensions, mypy-extensions, multimethod, annotated-types, typing-inspect, typeguard, pydantic-core, pydantic, pandera\n",
      "Successfully installed annotated-types-0.7.0 multimethod-1.10 mypy-extensions-1.0.0 pandera-0.19.3 pydantic-2.7.4 pydantic-core-2.18.4 typeguard-4.3.0 typing-extensions-4.12.2 typing-inspect-0.9.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "%pip install pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas core components\n",
    "* Series data type\n",
    "* DataFrame data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "5    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa \n",
    "\n",
    "# we can use array for creating a series\n",
    "s1 : pd.Series = pd.Series([1,2,3,4,5,6])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' type is unordered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandera\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# we can not use set for creating a series\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m s1 : pd\u001b[38;5;241m.\u001b[39mSeries \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries({\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m})\n\u001b[0;32m      6\u001b[0m s1\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandas\\core\\construction.py:642\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(\n\u001b[0;32m    634\u001b[0m         data,\n\u001b[0;32m    635\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    638\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39mallow_2d,\n\u001b[0;32m    639\u001b[0m     )\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 642\u001b[0m     _sanitize_non_ordered(data)\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;66;03m# materialize e.g. generators, convert e.g. tuples, abc.ValueView\u001b[39;00m\n\u001b[0;32m    644\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandas\\core\\construction.py:693\u001b[0m, in \u001b[0;36m_sanitize_non_ordered\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03mRaise only for unordered sets, e.g., not for dict_keys\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m)):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m type is unordered\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'set' type is unordered"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa \n",
    "\n",
    "# we can not use set for creating a series\n",
    "s1 : pd.Series = pd.Series({1,2,3,4,5,6})\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "5    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa \n",
    "\n",
    "# we can use tuple for creating a series\n",
    "s1 : pd.Series = pd.Series((1,2,3,4,5,6))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     50\n",
       "b      2\n",
       "c      6\n",
       "d     90\n",
       "e    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa \n",
    "\n",
    "# we can use Dictionary for creating a series\n",
    "s1 : pd.Series = pd.Series({\"a\":50,\n",
    "                            \"b\":2,\n",
    "                            \"c\":6,\n",
    "                            \"d\":90,\n",
    "                            \"e\":100\n",
    "                            \n",
    "                            })\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     1\n",
       "b     2\n",
       "c     3\n",
       "d     4\n",
       "e     5\n",
       "f     5\n",
       "g    65\n",
       "h    32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values : list[int] = [1,2,3,4,5,5,65,32]\n",
    "index1 : list[str] = ['a','b','c','d','e','f','g','h']\n",
    "\n",
    "ser : pd.Series = pd.Series(values,index=index1)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a1  a     1\n",
       "    b     2\n",
       "b1  c     3\n",
       "    d     4\n",
       "    e     5\n",
       "c1  f     5\n",
       "    g    65\n",
       "    h    32\n",
       "Name: Students, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values : list[int] = [1,2,3,4,5,5,65,32]\n",
    "index1 : list[list[str]] = [['a1','a1','b1','b1','b1','c1','c1','c1'],\n",
    "    ['a','b','c','d','e','f','g','h']]\n",
    "\n",
    "ser : pd.Series = pd.Series(values,index=index1, name='Students')\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>waqas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>haris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>arman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>rohan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>shayan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1       2\n",
       "0  1  90   waqas\n",
       "1  2  80   haris\n",
       "2  3  65   arman\n",
       "3  4  73   rohan\n",
       "4  5  89  shayan"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s1 : pd.Series = pd.Series([1,2,3,4,5],name='student id')\n",
    "s2 : pd.Series = pd.Series([90,80,65,73,89],name='score')\n",
    "s3 : pd.Series = pd.Series(['waqas','haris','arman','rohan','shayan'],name='name')\n",
    "\n",
    "define = pd.concat([s1,s2,s3],axis=1)\n",
    "define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student id</th>\n",
       "      <th>score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>waqas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>haris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>arman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>rohan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>shayan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student id  score    name\n",
       "0           1     90   waqas\n",
       "1           2     80   haris\n",
       "2           3     65   arman\n",
       "3           4     73   rohan\n",
       "4           5     89  shayan"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s1 : pd.Series = pd.Series([1,2,3,4,5],name='student id')\n",
    "s2 : pd.Series = pd.Series([90,80,65,73,89],name='score')\n",
    "s3 : pd.Series = pd.Series(['waqas','haris','arman','rohan','shayan'],name='name')\n",
    "\n",
    "define = pd.DataFrame({'student id':s1,'score':s2,'name':s3})\n",
    "define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "X  1  2  3\n",
       "Y  4  5  6\n",
       "Z  7  8  9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'Z'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data : list[list[int]] = [[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]\n",
    "\n",
    "define = pd.DataFrame(data,columns=['A','B','C'], index=['X','Y','Z'])\n",
    "display(define)\n",
    "display(define.columns)\n",
    "display(define.index)\n",
    "display(define.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D   E   F   G   H   I   J\n",
       "0   0   1   2   3   4   5   6   7   8   9\n",
       "1  10  11  12  13  14  15  16  17  18  19\n",
       "2  20  21  22  23  24  25  26  27  28  29\n",
       "3  30  31  32  33  34  35  36  37  38  39\n",
       "4  40  41  42  43  44  45  46  47  48  49\n",
       "5  50  51  52  53  54  55  56  57  58  59\n",
       "6  60  61  62  63  64  65  66  67  68  69\n",
       "7  70  71  72  73  74  75  76  77  78  79\n",
       "8  80  81  82  83  84  85  86  87  88  89\n",
       "9  90  91  92  93  94  95  96  97  98  99"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nptyping import Shape,NDArray\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data : NDArray[Shape['Size,Size'],Any] = np.arange(10*10).reshape(10,10)\n",
    "\n",
    "\n",
    "df : pd.DataFrame = pd.DataFrame(data,columns=list('ABCDEFGHIJ'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>bio</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adeel Solangi</td>\n",
       "      <td>Sindhi</td>\n",
       "      <td>V59OF92YF627HFY0</td>\n",
       "      <td>Donec lobortis eleifend condimentum. Cras dict...</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afzal Ghaffar</td>\n",
       "      <td>Sindhi</td>\n",
       "      <td>ENTOCR13RSCLZ6KU</td>\n",
       "      <td>Aliquam sollicitudin ante ligula, eget malesua...</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aamir Solangi</td>\n",
       "      <td>Sindhi</td>\n",
       "      <td>IAKPO3R4761JDRVG</td>\n",
       "      <td>Vestibulum pharetra libero et velit gravida eu...</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abla Dilmurat</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>5ZVOEPMJUI4MB4EN</td>\n",
       "      <td>Donec lobortis eleifend condimentum. Morbi ac ...</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adil Eli</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>6VTI8X6LL0MMPJCC</td>\n",
       "      <td>Vivamus id faucibus velit, id posuere leo. Mor...</td>\n",
       "      <td>6.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Kristín Sigurðardóttir</td>\n",
       "      <td>Icelandic</td>\n",
       "      <td>ZP5TBBYX6RI2UJ31</td>\n",
       "      <td>Cras dictum dolor lacinia lectus vehicula rutr...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Rohini Vasav</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>UEFML43TCGS04KWM</td>\n",
       "      <td>Ut accumsan, est vel fringilla varius, purus a...</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Sunil Kapoor</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>VY2A0APGVHK5NAW2</td>\n",
       "      <td>Proin tempus eu risus nec mattis. Ut dictum, l...</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Zamokuhle Zulu</td>\n",
       "      <td>isiZulu</td>\n",
       "      <td>XU7BX2F8M5PVZ1EF</td>\n",
       "      <td>Etiam congue dignissim volutpat. Phasellus tin...</td>\n",
       "      <td>8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Bhupesh Menon</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>0CEPNRDV98KT3ORP</td>\n",
       "      <td>Maecenas tempus neque ut porttitor malesuada. ...</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name   language                id  \\\n",
       "0             Adeel Solangi     Sindhi  V59OF92YF627HFY0   \n",
       "1             Afzal Ghaffar     Sindhi  ENTOCR13RSCLZ6KU   \n",
       "2             Aamir Solangi     Sindhi  IAKPO3R4761JDRVG   \n",
       "3             Abla Dilmurat     Uyghur  5ZVOEPMJUI4MB4EN   \n",
       "4                  Adil Eli     Uyghur  6VTI8X6LL0MMPJCC   \n",
       "..                      ...        ...               ...   \n",
       "192  Kristín Sigurðardóttir  Icelandic  ZP5TBBYX6RI2UJ31   \n",
       "193            Rohini Vasav      Hindi  UEFML43TCGS04KWM   \n",
       "194            Sunil Kapoor      Hindi  VY2A0APGVHK5NAW2   \n",
       "195          Zamokuhle Zulu    isiZulu  XU7BX2F8M5PVZ1EF   \n",
       "196           Bhupesh Menon      Hindi  0CEPNRDV98KT3ORP   \n",
       "\n",
       "                                                   bio  version  \n",
       "0    Donec lobortis eleifend condimentum. Cras dict...     6.10  \n",
       "1    Aliquam sollicitudin ante ligula, eget malesua...     1.88  \n",
       "2    Vestibulum pharetra libero et velit gravida eu...     7.27  \n",
       "3    Donec lobortis eleifend condimentum. Morbi ac ...     2.53  \n",
       "4    Vivamus id faucibus velit, id posuere leo. Mor...     6.49  \n",
       "..                                                 ...      ...  \n",
       "192  Cras dictum dolor lacinia lectus vehicula rutr...     2.80  \n",
       "193  Ut accumsan, est vel fringilla varius, purus a...     9.30  \n",
       "194  Proin tempus eu risus nec mattis. Ut dictum, l...     8.04  \n",
       "195  Etiam congue dignissim volutpat. Phasellus tin...     8.39  \n",
       "196  Maecenas tempus neque ut porttitor malesuada. ...     2.69  \n",
       "\n",
       "[197 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df : pd.DataFrame = pd.read_json('https://microsoftedge.github.io/Demos/json-dummy-data/64KB.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msep\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mheader\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"int | Sequence[int] | None | Literal['infer']\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Sequence[Hashable] | None | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | Literal[False] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'UsecolsArgType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DtypeArg | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'CSVEngine | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mapping[Hashable, Callable] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list[int] | int | Callable[[Hashable], bool] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | Sequence[Hashable] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Callable | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | dict[Hashable, str] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'CompressionOptions'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mencoding_errors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'strict'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | csv.Dialect | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mon_bad_lines\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Literal['high', 'legacy'] | None\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'StorageOptions | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype_backend\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DtypeBackend | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame | TextFileReader'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "Also supports optionally iterating or breaking of the file\n",
      "into chunks.\n",
      "\n",
      "Additional help can be found in the online docs for\n",
      "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filepath_or_buffer : str, path object or file-like object\n",
      "    Any valid string path is acceptable. The string could be a URL. Valid\n",
      "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "sep : str, default ','\n",
      "    Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "    C engine cannot automatically detect\n",
      "    the separator, but the Python parsing engine can, meaning the latter will\n",
      "    be used and automatically detect the separator from only the first valid\n",
      "    row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "    In addition, separators longer than 1 character and different from\n",
      "    ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "    the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "    to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "delimiter : str, optional\n",
      "    Alias for ``sep``.\n",
      "header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "    Row number(s) containing column labels and marking the start of the\n",
      "    data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
      "    are passed the behavior is identical to ``header=0`` and column\n",
      "    names are inferred from the first line of the file, if column\n",
      "    names are passed explicitly to ``names`` then the behavior is identical to\n",
      "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "    replace existing names. The header can be a list of integers that\n",
      "    specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "    e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "    skipped (e.g. 2 in this example is skipped). Note that this\n",
      "    parameter ignores commented lines and empty lines if\n",
      "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "    data rather than the first line of the file.\n",
      "names : Sequence of Hashable, optional\n",
      "    Sequence of column labels to apply. If the file contains a header row,\n",
      "    then you should explicitly pass ``header=0`` to override the column names.\n",
      "    Duplicates in this list are not allowed.\n",
      "index_col : Hashable, Sequence of Hashable or False, optional\n",
      "  Column(s) to use as row label(s), denoted either by column labels or column\n",
      "  indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
      "  will be formed for the row labels.\n",
      "\n",
      "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "  column as the index, e.g., when you have a malformed file with delimiters at\n",
      "  the end of each line.\n",
      "usecols : Sequence of Hashable or Callable, optional\n",
      "    Subset of columns to select, denoted either by column labels or column indices.\n",
      "    If list-like, all elements must either\n",
      "    be positional (i.e. integer indices into the document columns) or strings\n",
      "    that correspond to column names provided either by the user in ``names`` or\n",
      "    inferred from the document header row(s). If ``names`` are given, the document\n",
      "    header row(s) are not taken into account. For example, a valid list-like\n",
      "    ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "    To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "    preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "    for columns in ``['foo', 'bar']`` order or\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "    for ``['bar', 'foo']`` order.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the column\n",
      "    names, returning names where the callable function evaluates to ``True``. An\n",
      "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "    parsing time and lower memory usage.\n",
      "dtype : dtype or dict of {Hashable : dtype}, optional\n",
      "    Data type(s) to apply to either the whole dataset or individual columns.\n",
      "    E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
      "    Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "    to preserve and not interpret ``dtype``.\n",
      "    If ``converters`` are specified, they will be applied INSTEAD\n",
      "    of ``dtype`` conversion.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "\n",
      "        Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
      "        the default determines the ``dtype`` of the columns which are not explicitly\n",
      "        listed.\n",
      "engine : {'c', 'python', 'pyarrow'}, optional\n",
      "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "    is currently more feature-complete. Multithreading is currently only supported by\n",
      "    the pyarrow engine.\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "        The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
      "        are unsupported, or may not work correctly, with this engine.\n",
      "converters : dict of {Hashable : Callable}, optional\n",
      "    Functions for converting values in specified columns. Keys can either\n",
      "    be column labels or column indices.\n",
      "true_values : list, optional\n",
      "    Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
      "false_values : list, optional\n",
      "    Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
      "skipinitialspace : bool, default False\n",
      "    Skip spaces after delimiter.\n",
      "skiprows : int, list of int or Callable, optional\n",
      "    Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "    at the start of the file.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the row\n",
      "    indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
      "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "skipfooter : int, default 0\n",
      "    Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "nrows : int, optional\n",
      "    Number of rows of file to read. Useful for reading pieces of large files.\n",
      "na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
      "    Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
      "    per-column ``NA`` values.  By default the following values are interpreted as\n",
      "    ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
      "    \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
      "    \"n/a\", \"nan\", \"null \".\n",
      "\n",
      "keep_default_na : bool, default True\n",
      "    Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "    Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "\n",
      "    * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
      "      is appended to the default ``NaN`` values used for parsing.\n",
      "    * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "      the default ``NaN`` values are used for parsing.\n",
      "    * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "      the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "    * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "      strings will be parsed as ``NaN``.\n",
      "\n",
      "    Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
      "    ``na_values`` parameters will be ignored.\n",
      "na_filter : bool, default True\n",
      "    Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "    data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "    performance of reading a large file.\n",
      "verbose : bool, default False\n",
      "    Indicate number of ``NA`` values placed in non-numeric columns.\n",
      "\n",
      "    .. deprecated:: 2.2.0\n",
      "skip_blank_lines : bool, default True\n",
      "    If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
      "    The behavior is as follows:\n",
      "\n",
      "    * ``bool``. If ``True`` -> try parsing the index. Note: Automatically set to\n",
      "      ``True`` if ``date_format`` or ``date_parser`` arguments have been passed.\n",
      "    * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "      each as a separate date column.\n",
      "    * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
      "      as a single date column. Values are joined with a space before parsing.\n",
      "    * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
      "      result 'foo'. Values are joined with a space before parsing.\n",
      "\n",
      "    If a column or index cannot be represented as an array of ``datetime``,\n",
      "    say because of an unparsable value or a mixture of timezones, the column\n",
      "    or index will be returned unaltered as an ``object`` data type. For\n",
      "    non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "    :func:`~pandas.read_csv`.\n",
      "\n",
      "    Note: A fast-path exists for iso8601-formatted dates.\n",
      "infer_datetime_format : bool, default False\n",
      "    If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
      "    format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
      "    switch to a faster method of parsing them. In some cases this can increase\n",
      "    the parsing speed by 5-10x.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "        A strict version of this argument is now the default, passing it has no effect.\n",
      "\n",
      "keep_date_col : bool, default False\n",
      "    If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
      "    keep the original columns.\n",
      "date_parser : Callable, optional\n",
      "    Function to use for converting a sequence of string columns to an array of\n",
      "    ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "    conversion. pandas will try to call ``date_parser`` in three different ways,\n",
      "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "    (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
      "    string values from the columns defined by ``parse_dates`` into a single array\n",
      "    and pass that; and 3) call ``date_parser`` once for each row using one or\n",
      "    more strings (corresponding to the columns defined by ``parse_dates``) as\n",
      "    arguments.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "       Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "       :func:`~pandas.to_datetime` as-needed.\n",
      "date_format : str or dict of column -> format, optional\n",
      "    Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
      "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "    `strftime documentation\n",
      "    <https://docs.python.org/3/library/datetime.html\n",
      "    #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "    note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "    You can also pass:\n",
      "\n",
      "    - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "        time string (not necessarily in exactly the same format);\n",
      "    - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "        and you should probably use it along with `dayfirst`.\n",
      "\n",
      "    .. versionadded:: 2.0.0\n",
      "dayfirst : bool, default False\n",
      "    DD/MM format dates, international and European format.\n",
      "cache_dates : bool, default True\n",
      "    If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "    conversion. May produce significant speed-up when parsing duplicate\n",
      "    date strings, especially ones with timezone offsets.\n",
      "\n",
      "iterator : bool, default False\n",
      "    Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "    ``get_chunk()``.\n",
      "chunksize : int, optional\n",
      "    Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "    function to return a ``TextFileReader`` object for iteration.\n",
      "    See the `IO Tools docs\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "    for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "    Set to ``None`` for no decompression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "    other key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for Zstandard decompression using a\n",
      "    custom compression dictionary:\n",
      "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "        Added support for `.tar` files.\n",
      "\n",
      "    .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "thousands : str (length 1), optional\n",
      "    Character acting as the thousands separator in numerical values.\n",
      "decimal : str (length 1), default '.'\n",
      "    Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "lineterminator : str (length 1), optional\n",
      "    Character used to denote a line break. Only valid with C parser.\n",
      "quotechar : str (length 1), optional\n",
      "    Character used to denote the start and end of a quoted item. Quoted\n",
      "    items can include the ``delimiter`` and it will be ignored.\n",
      "quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
      "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "    ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
      "    characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
      "    or ``lineterminator``.\n",
      "doublequote : bool, default True\n",
      "   When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "   whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "   field as a single ``quotechar`` element.\n",
      "escapechar : str (length 1), optional\n",
      "    Character used to escape other characters.\n",
      "comment : str (length 1), optional\n",
      "    Character indicating that the remainder of line should not be parsed.\n",
      "    If found at the beginning\n",
      "    of a line, the line will be ignored altogether. This parameter must be a\n",
      "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "    fully commented lines are ignored by the parameter ``header`` but not by\n",
      "    ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "    treated as the header.\n",
      "encoding : str, optional, default 'utf-8'\n",
      "    Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "    standard encodings\n",
      "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "encoding_errors : str, optional, default 'strict'\n",
      "    How encoding errors are treated. `List of possible values\n",
      "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "dialect : str or csv.Dialect, optional\n",
      "    If provided, this parameter will override values (default or not) for the\n",
      "    following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "    ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "    override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "    documentation for more details.\n",
      "on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
      "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "    Allowed values are :\n",
      "\n",
      "    - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "    - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
      "    - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "        - Callable, function with signature\n",
      "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "          If the function returns ``None``, the bad line will be ignored.\n",
      "          If the function returns a new ``list`` of strings with more elements than\n",
      "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "          Only supported when ``engine='python'``\n",
      "\n",
      "    .. versionchanged:: 2.2.0\n",
      "\n",
      "        - Callable, function with signature\n",
      "          as described in `pyarrow documentation\n",
      "          <https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html\n",
      "          #pyarrow.csv.ParseOptions.invalid_row_handler>`_ when ``engine='pyarrow'``\n",
      "\n",
      "delim_whitespace : bool, default False\n",
      "    Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "    used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "    is set to ``True``, nothing should be passed in for the ``delimiter``\n",
      "    parameter.\n",
      "\n",
      "    .. deprecated:: 2.2.0\n",
      "        Use ``sep=\"\\s+\"`` instead.\n",
      "low_memory : bool, default True\n",
      "    Internally process the file in chunks, resulting in lower memory use\n",
      "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "    types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "    Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "    regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
      "    chunks. (Only valid with C parser).\n",
      "memory_map : bool, default False\n",
      "    If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "    directly onto memory and access the data directly from there. Using this\n",
      "    option can improve performance because there is no longer any I/O overhead.\n",
      "float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
      "    Specifies which converter the C engine should use for floating-point\n",
      "    values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "    ``'legacy'`` for the original lower precision pandas converter, and\n",
      "    ``'round_trip'`` for the round-trip converter.\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "    Back-end data type applied to the resultant :class:`DataFrame`\n",
      "    (still experimental). Behaviour is as follows:\n",
      "\n",
      "    * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "      (default).\n",
      "    * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "      DataFrame.\n",
      "\n",
      "    .. versionadded:: 2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or TextFileReader\n",
      "    A comma-separated values (csv) file is returned as two-dimensional\n",
      "    data structure with labeled axes.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "read_table : Read general delimited file into DataFrame.\n",
      "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\u001b[1;31mFile:\u001b[0m      d:\\anaconda\\envs\\'py-11'\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_check_fn_code',\n",
       " 'between',\n",
       " 'eq',\n",
       " 'equal_to',\n",
       " 'equal_to',\n",
       " 'from_builtin_check_name',\n",
       " 'ge',\n",
       " 'get_backend',\n",
       " 'get_builtin_check_fn',\n",
       " 'greater_than',\n",
       " 'greater_than',\n",
       " 'greater_than_or_equal_to',\n",
       " 'greater_than_or_equal_to',\n",
       " 'gt',\n",
       " 'in_range',\n",
       " 'in_range',\n",
       " 'isin',\n",
       " 'isin',\n",
       " 'le',\n",
       " 'less_than',\n",
       " 'less_than',\n",
       " 'less_than_or_equal_to',\n",
       " 'less_than_or_equal_to',\n",
       " 'lt',\n",
       " 'ne',\n",
       " 'not_equal_to',\n",
       " 'not_equal_to',\n",
       " 'notin',\n",
       " 'notin',\n",
       " 'one_sample_ttest',\n",
       " 'register_backend',\n",
       " 'register_builtin_check_fn',\n",
       " 'str_contains',\n",
       " 'str_contains',\n",
       " 'str_endswith',\n",
       " 'str_endswith',\n",
       " 'str_length',\n",
       " 'str_length',\n",
       " 'str_matches',\n",
       " 'str_matches',\n",
       " 'str_startswith',\n",
       " 'str_startswith',\n",
       " 'two_sample_ttest',\n",
       " 'unique_values_eq',\n",
       " 'unique_values_eq']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandera as pa\n",
    "dir(pa.Check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slicing and indexing\n",
    "\n",
    "* variable[index]\n",
    "* dataFrame:\n",
    "  * loc\n",
    "  * iloc\n",
    "  * at\n",
    "  * iat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 : pd.Series = pd.Series([1,2,3,4,5])\n",
    "display(s1)\n",
    "\n",
    "# applying slicing\n",
    "display(s1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 : pd.Series = pd.Series([1,2,3,4,5])\n",
    "display(s1)\n",
    "\n",
    "# applying slicing\n",
    "display(s1[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "d    4\n",
       "e    5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 : pd.Series = pd.Series([1,2,3,4,5],index=['a','b','c','d','e'])\n",
    "display(s1)\n",
    "\n",
    "# applying slicing\n",
    "display(s1[1:3])\n",
    "display(s1.iloc[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "d    4\n",
       "e    5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 : pd.Series = pd.Series([1,2,3,4,5],index=['a','b','c','d','e'])\n",
    "display(s1)\n",
    "\n",
    "# applying slicing\n",
    "display(s1[1:3])\n",
    "display(s1.loc['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "d    4\n",
       "e    5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 : pd.Series = pd.Series([1,2,3,4,5],index=['a','b','c','d','e'])\n",
    "display(s1)\n",
    "\n",
    "# applying slicing\n",
    "display(s1[1:3])\n",
    "display(s1.iat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "d    4\n",
       "e    5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 : pd.Series = pd.Series([1,2,3,4,5],index=['a','b','c','d','e'])\n",
    "display(s1)\n",
    "\n",
    "# applying slicing\n",
    "display(s1[1:3])\n",
    "display(s1.at['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "\n",
    "# data to validate\n",
    "df = pd.DataFrame({\n",
    "    \"column1\": [1, 4, 0, 10, 9],\n",
    "    \"column2\": [-1.3, -1.4, -2.9, -10.1, -20.4],\n",
    "    \"column3\": [\"value_1\", \"value_2\", \"value_3\", \"value_2\", \"value_1\"],\n",
    "})\n",
    "\n",
    "# define schema\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int, checks=pa.Check.le(10)),\n",
    "    \"column2\": pa.Column(float, checks=pa.Check.lt(-1.2)),\n",
    "    \"column3\": pa.Column(str, checks=[\n",
    "        pa.Check.str_startswith(\"value_\"),\n",
    "        # define custom checks as functions that take a series as input and\n",
    "        # outputs a boolean or boolean Series\n",
    "        pa.Check(lambda s: s.str.split(\"_\", expand=True).shape[1] == 2)\n",
    "    ]),\n",
    "})\n",
    "\n",
    "validated_df = schema(df)\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[  Operator            Name Example    Try it\n",
       " 0        +        Addition   x + y  Try it »\n",
       " 1        -     Subtraction   x - y  Try it »\n",
       " 2        *  Multiplication   x * y  Try it »\n",
       " 3        /        Division   x / y  Try it »\n",
       " 4        %         Modulus   x % y  Try it »\n",
       " 5       **  Exponentiation  x ** y  Try it »\n",
       " 6       //  Floor division  x // y  Try it »,\n",
       "    Operator        Example         Same As    Try it\n",
       " 0         =          x = 5           x = 5  Try it »\n",
       " 1        +=         x += 3       x = x + 3  Try it »\n",
       " 2        -=         x -= 3       x = x - 3  Try it »\n",
       " 3        *=         x *= 3       x = x * 3  Try it »\n",
       " 4        /=         x /= 3       x = x / 3  Try it »\n",
       " 5        %=         x %= 3       x = x % 3  Try it »\n",
       " 6       //=        x //= 3      x = x // 3  Try it »\n",
       " 7       **=        x **= 3      x = x ** 3  Try it »\n",
       " 8        &=         x &= 3       x = x & 3  Try it »\n",
       " 9        |=         x |= 3       x = x | 3  Try it »\n",
       " 10       ^=         x ^= 3       x = x ^ 3  Try it »\n",
       " 11      >>=        x >>= 3      x = x >> 3  Try it »\n",
       " 12      <<=        x <<= 3      x = x << 3  Try it »\n",
       " 13       :=  print(x := 3)  x = 3 print(x)  Try it »,\n",
       "   Operator                      Name Example    Try it\n",
       " 0       ==                     Equal  x == y  Try it »\n",
       " 1       !=                 Not equal  x != y  Try it »\n",
       " 2        >              Greater than   x > y  Try it »\n",
       " 3        <                 Less than   x < y  Try it »\n",
       " 4       >=  Greater than or equal to  x >= y  Try it »\n",
       " 5       <=     Less than or equal to  x <= y  Try it »,\n",
       "   Operator                                        Description  \\\n",
       " 0      and           Returns True if both statements are true   \n",
       " 1       or      Returns True if one of the statements is true   \n",
       " 2      not  Reverse the result, returns False if the resul...   \n",
       " \n",
       "                  Example    Try it  \n",
       " 0       x < 5 and x < 10  Try it »  \n",
       " 1         x < 5 or x < 4  Try it »  \n",
       " 2  not(x < 5 and x < 10)  Try it »  ,\n",
       "   Operator                                        Description     Example  \\\n",
       " 0       is  Returns True if both variables are the same ob...      x is y   \n",
       " 1   is not  Returns True if both variables are not the sam...  x is not y   \n",
       " \n",
       "      Try it  \n",
       " 0  Try it »  \n",
       " 1  Try it »  ,\n",
       "   Operator                                        Description     Example  \\\n",
       " 0       in  Returns True if a sequence with the specified ...      x in y   \n",
       " 1   not in  Returns True if a sequence with the specified ...  x not in y   \n",
       " \n",
       "      Try it  \n",
       " 0  Try it »  \n",
       " 1  Try it »  ,\n",
       "   Operator                  Name  \\\n",
       " 0        &                   AND   \n",
       " 1        |                    OR   \n",
       " 2        ^                   XOR   \n",
       " 3        ~                   NOT   \n",
       " 4       <<  Zero fill left shift   \n",
       " 5       >>    Signed right shift   \n",
       " \n",
       "                                          Description Example    Try it  \n",
       " 0              Sets each bit to 1 if both bits are 1   x & y  Try it »  \n",
       " 1         Sets each bit to 1 if one of two bits is 1   x | y  Try it »  \n",
       " 2    Sets each bit to 1 if only one of two bits is 1   x ^ y  Try it »  \n",
       " 3                               Inverts all the bits      ~x  Try it »  \n",
       " 4  Shift left by pushing zeros in from the right ...  x << 2  Try it »  \n",
       " 5  Shift right by pushing copies of the leftmost ...  x >> 2  Try it »  ,\n",
       "                                Operator  \\\n",
       " 0                                    ()   \n",
       " 1                                    **   \n",
       " 2                              +x -x ~x   \n",
       " 3                              * / // %   \n",
       " 4                                   + -   \n",
       " 5                                 << >>   \n",
       " 6                                     &   \n",
       " 7                                     ^   \n",
       " 8                                     |   \n",
       " 9   == != > >= < <= is is not in not in   \n",
       " 10                                  not   \n",
       " 11                                  and   \n",
       " 12                                   or   \n",
       " \n",
       "                                           Description    Try it  \n",
       " 0                                         Parentheses  Try it »  \n",
       " 1                                      Exponentiation  Try it »  \n",
       " 2            Unary plus, unary minus, and bitwise NOT  Try it »  \n",
       " 3   Multiplication, division, floor division, and ...  Try it »  \n",
       " 4                            Addition and subtraction  Try it »  \n",
       " 5                       Bitwise left and right shifts  Try it »  \n",
       " 6                                         Bitwise AND  Try it »  \n",
       " 7                                         Bitwise XOR  Try it »  \n",
       " 8                                          Bitwise OR  Try it »  \n",
       " 9     Comparisons, identity, and membership operators  Try it »  \n",
       " 10                                        Logical NOT  Try it »  \n",
       " 11                                                AND  Try it »  \n",
       " 12                                                 OR  Try it »  ]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operator</th>\n",
       "      <th>Name</th>\n",
       "      <th>Example</th>\n",
       "      <th>Try it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>Addition</td>\n",
       "      <td>x + y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>Subtraction</td>\n",
       "      <td>x - y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*</td>\n",
       "      <td>Multiplication</td>\n",
       "      <td>x * y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/</td>\n",
       "      <td>Division</td>\n",
       "      <td>x / y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%</td>\n",
       "      <td>Modulus</td>\n",
       "      <td>x % y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>**</td>\n",
       "      <td>Exponentiation</td>\n",
       "      <td>x ** y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>//</td>\n",
       "      <td>Floor division</td>\n",
       "      <td>x // y</td>\n",
       "      <td>Try it »</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Operator            Name Example    Try it\n",
       "0        +        Addition   x + y  Try it »\n",
       "1        -     Subtraction   x - y  Try it »\n",
       "2        *  Multiplication   x * y  Try it »\n",
       "3        /        Division   x / y  Try it »\n",
       "4        %         Modulus   x % y  Try it »\n",
       "5       **  Exponentiation  x ** y  Try it »\n",
       "6       //  Floor division  x // y  Try it »"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfl : list[pd.DataFrame] = pd.read_html(\"https://www.w3schools.com/python/python_operators.asp\")\n",
    "display(dfl)\n",
    "display(dfl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('21:41:45', 'Altaf Hussain', 'PIAIC-173738'),\n",
       " ('21:41:54', 'Hina Zargham', 'PIAIC101499'),\n",
       " ('21:41:54', 'Ahmed Siddiqui', 'PIAIC123456'),\n",
       " ('21:42:00', 'Rehan Baig - PIAIC73919', 'PIAIC73919'),\n",
       " ('21:42:03', '.', 'PIAIC210905'),\n",
       " ('21:42:11', 'Arshad Siddiqui', 'PIAIC120702'),\n",
       " ('21:42:13', 'Azfar Suhail', 'PIAIC218333'),\n",
       " ('21:42:20', 'Ayesha Arshad', 'PIAIC-225620'),\n",
       " ('21:42:34', 'Arif Najmi', 'PIAIC 125657'),\n",
       " ('21:42:37', 'Ahmed', 'PIAIC-216511'),\n",
       " ('21:42:46', 'M Qasim', 'PIAIC178397'),\n",
       " ('21:42:59', 'IMRAN', 'PIAIC216423'),\n",
       " ('21:43:04', 'Ahmed', 'PIAIC-216511'),\n",
       " ('21:43:29', 'Zeeshan Abbas', 'PIAIC221479'),\n",
       " ('21:44:12', 'Ahsan', 'PIAIC185091')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>Roll No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21:41:45</td>\n",
       "      <td>Altaf Hussain</td>\n",
       "      <td>PIAIC-173738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21:41:54</td>\n",
       "      <td>Hina Zargham</td>\n",
       "      <td>PIAIC101499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21:41:54</td>\n",
       "      <td>Ahmed Siddiqui</td>\n",
       "      <td>PIAIC123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21:42:00</td>\n",
       "      <td>Rehan Baig - PIAIC73919</td>\n",
       "      <td>PIAIC73919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21:42:03</td>\n",
       "      <td>.</td>\n",
       "      <td>PIAIC210905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21:42:11</td>\n",
       "      <td>Arshad Siddiqui</td>\n",
       "      <td>PIAIC120702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21:42:13</td>\n",
       "      <td>Azfar Suhail</td>\n",
       "      <td>PIAIC218333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21:42:20</td>\n",
       "      <td>Ayesha Arshad</td>\n",
       "      <td>PIAIC-225620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21:42:34</td>\n",
       "      <td>Arif Najmi</td>\n",
       "      <td>PIAIC 125657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21:42:37</td>\n",
       "      <td>Ahmed</td>\n",
       "      <td>PIAIC-216511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21:42:46</td>\n",
       "      <td>M Qasim</td>\n",
       "      <td>PIAIC178397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21:42:59</td>\n",
       "      <td>IMRAN</td>\n",
       "      <td>PIAIC216423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21:43:04</td>\n",
       "      <td>Ahmed</td>\n",
       "      <td>PIAIC-216511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21:43:29</td>\n",
       "      <td>Zeeshan Abbas</td>\n",
       "      <td>PIAIC221479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21:44:12</td>\n",
       "      <td>Ahsan</td>\n",
       "      <td>PIAIC185091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time                     Name       Roll No\n",
       "0   21:41:45            Altaf Hussain  PIAIC-173738\n",
       "1   21:41:54             Hina Zargham   PIAIC101499\n",
       "2   21:41:54           Ahmed Siddiqui   PIAIC123456\n",
       "3   21:42:00  Rehan Baig - PIAIC73919    PIAIC73919\n",
       "4   21:42:03                        .   PIAIC210905\n",
       "5   21:42:11          Arshad Siddiqui   PIAIC120702\n",
       "6   21:42:13             Azfar Suhail   PIAIC218333\n",
       "7   21:42:20            Ayesha Arshad  PIAIC-225620\n",
       "8   21:42:34               Arif Najmi  PIAIC 125657\n",
       "9   21:42:37                    Ahmed  PIAIC-216511\n",
       "10  21:42:46                  M Qasim   PIAIC178397\n",
       "11  21:42:59                    IMRAN   PIAIC216423\n",
       "12  21:43:04                    Ahmed  PIAIC-216511\n",
       "13  21:43:29            Zeeshan Abbas   PIAIC221479\n",
       "14  21:44:12                    Ahsan   PIAIC185091"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x : str = \"\"\"\n",
    "20:03:10 From Dr. Ghulam Shabbir to Everyone:\n",
    "\tAoA Honorable Sir Qasim Sb. Stay blessed always iA.\n",
    "20:03:41 From M Qasim to Everyone:\n",
    "\tsir aj payare lag rahy hy\n",
    "20:04:02 From Dr. Ghulam Shabbir to Everyone:\n",
    "\tFantastic\n",
    "20:04:06 From jhon wick to Qasim(CGAIO)(Direct Message):\n",
    "\tsir aj zia khan sir ne nahi ana\n",
    "20:04:37 From jhon wick to Everyone:\n",
    "\tReacted to \"sir aj payare lag ra...\" with 😂\n",
    "20:04:44 From M Qasim to Everyone:\n",
    "\tReacted to \"sir aj payare lag ra...\" with 😂\n",
    "20:04:54 From M Qasim to Everyone:\n",
    "\tRemoved a 😂 reaction from \"sir aj payare lag ra...\"\n",
    "20:04:56 From M Qasim to Everyone:\n",
    "\tReacted to \"sir aj payare lag ra...\" with 😂\n",
    "20:04:57 From M Qasim to Everyone:\n",
    "\tRemoved a 😂 reaction from \"sir aj payare lag ra...\"\n",
    "20:06:04 From Abdullah to Everyone:\n",
    "\tsir ap kal ki class me ni ayen gy kia??\n",
    "20:06:04 From M Qasim to Everyone:\n",
    "\tSir Faisalabad b a rahy hy kya ap?\n",
    "20:06:49 From Yasir to Everyone:\n",
    "\tSir generative ai ki class online b hogi na?????\n",
    "20:07:17 From Sheikh Hamza to Everyone:\n",
    "\tSir data analytics ke liye maths statistics and probability ani chaye??\n",
    "20:07:24 From Yasir to Everyone:\n",
    "\tReplying to \"Sir generative ai ki...\"\n",
    "\t\n",
    "\t@Ikhlas Bhojani PLease ask from sir?\n",
    "20:07:57 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"Sir generative ai ki...\"\n",
    "\t\n",
    "\tok wait\n",
    "20:08:52 From Dr. Ghulam Shabbir to Everyone:\n",
    "\tSir Qasim Sb. You were frequently discussed and were given honored and salute in our today's class at Islamabad. Dr. Ghulam Shabbir\n",
    "20:09:12 From STONE to Everyone:\n",
    "\tReacted to \"Sir Qasim Sb. You we...\" with 👍\n",
    "20:09:15 From Hatif Humayun to Everyone:\n",
    "\tReacted to \"Sir Qasim Sb. You we...\" with 👍\n",
    "20:09:19 From Dr. Ghulam Shabbir to Everyone:\n",
    "\tReacted to \"Sir Qasim Sb. You we...\" with 👍\n",
    "20:09:27 From STONE to Everyone:\n",
    "\tRemoved a 👍 reaction from \"Sir Qasim Sb. You we...\"\n",
    "20:09:33 From STONE to Everyone:\n",
    "\tReacted to \"Sir Qasim Sb. You we...\" with 👍\n",
    "20:09:34 From STONE to Everyone:\n",
    "\tRemoved a 👍 reaction from \"Sir Qasim Sb. You we...\"\n",
    "20:12:02 From Amanat Wattoo to Everyone:\n",
    "\tPd kia convention h\n",
    "20:12:20 From Amanat Wattoo to Everyone:\n",
    "\tYa koi or be naam de skte hn\n",
    "20:12:33 From farhan to Everyone:\n",
    "\tConvention hey\n",
    "20:12:50 From KifayatUllah to Everyone:\n",
    "\tscreen is not visible to me, may be network issue or something else\n",
    "20:14:16 From Rehan Alı WAKKAS to Everyone:\n",
    "\tImport pandas as pd and import pandora as pa.\n",
    "\tWhat is pd and pa ?\n",
    "20:14:28 From farhan to Everyone:\n",
    "\tJust names\n",
    "20:15:06 From Ikhlas Bhojani to Everyone:\n",
    "\tkoi question ho tw hand raise kriyea jese i moka milega me unmute krdonga\n",
    "20:15:41 From Talha to Everyone:\n",
    "\tReplying to \"Import pandas as pd ...\"\n",
    "\t\n",
    "\tAlias, instead of writing long words pandas and pandora, we can write pd and pa as their short form\n",
    "20:15:45 From Rehan Alı WAKKAS to Everyone:\n",
    "\t@Ikhlas Bhojani  \n",
    "\tImport pandas as pd and import pandora as pa.\n",
    "\tWhat is pd and pa ?\n",
    "20:16:25 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani  \n",
    "\tIm...\"\n",
    "\t\n",
    "\talias\n",
    "20:16:43 From Jazil Hashmi to Everyone:\n",
    "\tImport pandas could not be resolved from source. Why is this error coming? @Ikhlas Bhojani\n",
    "20:16:55 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani  \n",
    "\tIm...\"\n",
    "\t\n",
    "\tlike nick name\n",
    "20:17:36 From Ikhlas Bhojani to Everyone:\n",
    "\t!pip install pandas\n",
    "20:17:46 From Rehan Alı WAKKAS to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani  \n",
    "\tIm...\"\n",
    "\t\n",
    "\tDo they refer to Directories or what ?\n",
    "20:19:58 From Abdullah to Everyone:\n",
    "\tPandas is usually imported under the pd alias. alias: In Python alias are an alternate name for referring to the same thing. Create an alias with the as keyword while importing: import pandas as pd. Now the Pandas package can be referred to as pd instead of pandas .\n",
    "20:20:30 From farhan to Everyone:\n",
    "\tThese are nicknames used by community\n",
    "20:25:02 From ahsan rasheed to Everyone:\n",
    "\tMary kush lectures rah gy hain\n",
    "20:25:15 From ahsan rasheed to Everyone:\n",
    "\tKia ya lecture record ho rhy hain\n",
    "20:25:23 From ABDUL KHALIQ to Everyone:\n",
    "\tg\n",
    "20:25:26 From ABDUL KHALIQ to Everyone:\n",
    "\tyoutube\n",
    "20:25:31 From ABDUL KHALIQ to Everyone:\n",
    "\tpanaverse dao\n",
    "20:25:48 From ahsan rasheed to Everyone:\n",
    "\tThanks\n",
    "20:26:30 From Kamran Ahmed to Everyone:\n",
    "\ttabular form in panada\n",
    "20:26:46 From Sarwar Faridi to Everyone:\n",
    "\tTABULAR\n",
    "20:26:54 From Sarwar Faridi to Everyone:\n",
    "\t2D\n",
    "20:26:57 From Kamran Ahmed to Everyone:\n",
    "\tindex value also shown\n",
    "20:27:06 From Ahmed Siddiqui to Everyone:\n",
    "\tmatrix\n",
    "20:27:07 From Kamal Hassan to Everyone:\n",
    "\tseries men indexing h or tabular form mn h\n",
    "20:29:56 From Kaleem to Everyone:\n",
    "\tsir series ma duplicate values bhi dy kar daikhain!!\n",
    "20:35:09 From Zeeshan Abbas to Everyone:\n",
    "\tSir what is INT64\n",
    "20:37:19 From Ikhlas Bhojani to Everyone:\n",
    "\tkoi question he tw hand raise krke rakhen\n",
    "20:37:51 From Zeeshan Abbas to Everyone:\n",
    "\tmera question hai what is INT64\n",
    "20:38:04 From Abdullah to Everyone:\n",
    "\tsmj e ni aya \n",
    "\trepeat krwa dyen\n",
    "20:39:23 From Altaf Hussain to Everyone:\n",
    "\tJust like Chart of accounts in Accounting...\n",
    "20:39:44 From Ahmed Siddiqui to Everyone:\n",
    "\tReacted to \"Just like Chart of a...\" with 👍\n",
    "20:40:40 From hi to Everyone:\n",
    "\twhat is int 64\n",
    "20:40:45 From hi to Everyone:\n",
    "\tdtype: int 64\n",
    "20:40:54 From Zeeshan Abbas to Everyone:\n",
    "\tSir why is showing INT64 in below\n",
    "20:40:58 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"mera question hai wh...\"\n",
    "\t\n",
    "\ttype hoti he data ki\n",
    "20:42:24 From Kaleem to Everyone:\n",
    "\tin our structure data types of data we use key, value /key, pair values to define our data, how to translate that data Series?\n",
    "20:42:27 From Asif Ali Shaikh to Everyone:\n",
    "\tint 64 is memory\n",
    "20:42:44 From Asif Ali Shaikh to Everyone:\n",
    "\tWeb3\n",
    "20:45:11 From Zeeshan Abbas to Everyone:\n",
    "\tReacted to \"Web3\" with 👍\n",
    "20:46:15 From Galaxy to Everyone:\n",
    "\tSir g account udaar dy dy\n",
    "20:46:25 From Galaxy to Everyone:\n",
    "\tReacted to Sir g account udaar ... with \"😂\"\n",
    "20:46:40 From Ayesha Arshad to Everyone:\n",
    "\tReacted to \"Sir g account udaar ...\" with 😂\n",
    "20:46:40 From Ayesha Arshad to Everyone:\n",
    "\tRemoved a 😂 reaction from \"Sir g account udaar ...\"\n",
    "20:46:41 From jhon wick to Everyone:\n",
    "\tReacted to \"Sir g account udaar ...\" with 😂\n",
    "20:46:43 From Ayesha Arshad to Everyone:\n",
    "\tReacted to \"Sir g account udaar ...\" with 😂\n",
    "20:46:54 From Taif Ullah to Everyone:\n",
    "\tis bing equal to gpt 4\n",
    "20:49:29 From fahad rasheed to Everyone:\n",
    "\t2 dimension data hy pora select krna parhyga \"\" mn\n",
    "20:49:29 From Azfar Suhail to Everyone:\n",
    "\tfrom nptyping import DataFrame as DF, Structure as S\n",
    "\t\n",
    "\ts2 : DF[S[\"Abc : str\"]] = pd.Series(['a','b','c','d','e'])\n",
    "\ts2\n",
    "20:49:29 From Azfar Suhail to Everyone:\n",
    "\tthis is working\n",
    "20:51:57 From Saboor Hussain to Everyone:\n",
    "\tReacted to \"Sir g account udaa...\" with 😂\n",
    "20:51:59 From Saboor Hussain to Everyone:\n",
    "\tRemoved a 😂 from \"Sir g account udaa...\"\n",
    "20:58:40 From jhon wick to Everyone:\n",
    "\tyes\n",
    "20:59:04 From farhan to Everyone:\n",
    "\tKindly unmute\n",
    "20:59:22 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"Kindly unmute\"\n",
    "\t\n",
    "\twait\n",
    "21:00:43 From PIAIC80919 Muhammad Asad to Everyone:\n",
    "\tAssalamu Aliakum\n",
    "21:01:33 From Faizan Hassan to Everyone:\n",
    "\ts1.name kar k kar saktay hon ge\n",
    "21:01:43 From PIAIC80919 Muhammad Asad to Everyone:\n",
    "\tI joined late on zoom meet so kindly share links that sir share until now\n",
    "21:02:26 From Taif Ullah to Everyone:\n",
    "\tReplying to \"I joined late on zoo...\"\n",
    "\t\n",
    "\tevery thing will be on github\n",
    "21:04:19 From PIAIC80919 Muhammad Asad to Everyone:\n",
    "\tNumpy aur Pandas kay liya sir nay koi book share ki hai kay nahi\n",
    "21:04:42 From Amanat Wattoo to Everyone:\n",
    "\tReplying to \"Numpy aur Pandas kay...\"\n",
    "\t\n",
    "\tno\n",
    "21:05:21 From PIAIC80919 Muhammad Asad to Everyone:\n",
    "\taur python kay liya koi alag WhatsApp group hai to please uska b link share kardien\n",
    "21:06:00 From Amanat Wattoo to Everyone:\n",
    "\tReplying to \"aur python kay liya ...\"\n",
    "\t\n",
    "\tno koi group nhi bnia h\n",
    "21:07:17 From Abdullah to Everyone:\n",
    "\tupper array wala code knsa ha??\n",
    "21:07:51 From Hamza to Everyone:\n",
    "\t\"Shape\", \"Shape\"\n",
    "21:08:10 From Hamza to Everyone:\n",
    "\t\"Size\", \"Size\"\n",
    "21:08:26 From SheikhMAqib to Everyone:\n",
    "\tDouble coat\n",
    "21:08:33 From Azfar Suhail to Everyone:\n",
    "\tShape turtle se import kara hai\n",
    "21:08:51 From Azfar Suhail to Everyone:\n",
    "\tshape nptyping se import nhi howa\n",
    "21:09:34 From Muhammad Uzair to Everyone:\n",
    "\tshape galat import ha\n",
    "21:09:35 From Khadija Zahid to Everyone:\n",
    "\tshape ko kindly ek br explain kr den dbra\n",
    "21:09:38 From PIAIC80919 Muhammad Asad to Qasim(CGAIO)(Direct Message):\n",
    "\tAssalamu Aliakum Sir Kindly sir mujhe bta dien k Data Science kay liya Math aur Statistic kay kon si books and courses hum karien\n",
    "21:09:50 From Yasir to Everyone:\n",
    "\tshape import\n",
    "21:09:53 From Yasir to Everyone:\n",
    "\tmissing\n",
    "21:09:56 From Muhammad Uzair to Everyone:\n",
    "\tfrom import typing shape\n",
    "21:10:11 From Saboor Hussain to Everyone:\n",
    "\tsir\n",
    "21:10:19 From Saboor Hussain to Everyone:\n",
    "\taap nptyping se shape ko import karen\n",
    "21:10:21 From Yasir to Everyone:\n",
    "\timport nhi kia shape\n",
    "21:10:24 From farhan to Everyone:\n",
    "\tShape import nahi thi\n",
    "21:10:25 From Azfar Suhail to Everyone:\n",
    "\tturtle se import kara hai\n",
    "21:14:10 From sadia to Everyone:\n",
    "\tcan we get values 0 1 2 3 4 5 6 7 8 in vertical, abhi data horizontal arha hai\n",
    "21:18:10 From Faiz M to Everyone:\n",
    "\tSir chezy hard sy hard hoti ja rahe hy. aaj tho sir k oper oper ja raha hy.\n",
    "21:18:56 From Qasim(CGAIO) to Everyone:\n",
    "\thttps://www.w3schools.com/python/pandas/data.js\n",
    "21:19:20 From Khadija Zahid to Everyone:\n",
    "\thtml wala b ek br code dekha k bta de plz\n",
    "21:19:22 From Abdullah to Everyone:\n",
    "\tkindly class k bd groups me sessions ka link send kr dia kryen\n",
    "21:21:27 From Abdullah to Everyone:\n",
    "\tReplying to \"kindly class k bd gr...\"\n",
    "\t\n",
    "\t@Ikhlas Bhojani\n",
    "21:22:11 From Ahmed Siddiqui to Everyone:\n",
    "\twhat if data size in millions, what kind of preprocessing is required before handing over to pandas?\n",
    "21:22:41 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"kindly class k bd gr...\"\n",
    "\t\n",
    "\tme ap logo ke group me nhi hn\n",
    "21:22:59 From Abdullah to Everyone:\n",
    "\tReplying to \"kindly class k bd gr...\"\n",
    "\t\n",
    "\tbro sir sy kah dyen \n",
    "\tya sir Imran sy request kr dyen\n",
    "21:24:13 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"html wala b ek br co...\"\n",
    "\t\n",
    "\tpd.read_html(\"url\")\n",
    "21:26:02 From Kaleem to Everyone:\n",
    "\thow to make identical data ?\n",
    "21:26:19 From Afifa Dar to Everyone:\n",
    "\tcolmn3 k chexk me ==2 se kya horaha ?\n",
    "21:29:40 From PIAIC80919 Muhammad Asad to Qasim(CGAIO)(Direct Message):\n",
    "\tsir assignment b day dein practice kay liya\n",
    "21:32:29 From Ali Zar FSD to Everyone:\n",
    "\tsliding\n",
    "21:32:41 From Ali Zar FSD to Everyone:\n",
    "\tlikha gya sir\n",
    "21:33:00 From fahad rasheed to Everyone:\n",
    "\tsir thora data large kryn plx\n",
    "21:33:18 From fahad rasheed to Everyone:\n",
    "\tfor slicing thora data bardhae\n",
    "21:39:55 From raheela to Everyone:\n",
    "\tName is tort ???\n",
    "21:40:46 From Naveed Delattre to Everyone:\n",
    "\tit’s toad\n",
    "21:41:45 From Altaf Hussain to Everyone:\n",
    "\tPIAIC-173738\n",
    "21:41:51 From Hamza to Everyone:\n",
    "\tPIAIC-201785\n",
    "21:41:52 From jhon wick to Everyone:\n",
    "\tpiaic 223880\n",
    "21:41:54 From Hina Zargham to Everyone:\n",
    "\tPIAIC101499\n",
    "21:41:54 From Hatif Humayun to Everyone:\n",
    "\tPIAIC-52822\n",
    "21:41:54 From Ahmed Siddiqui to Everyone:\n",
    "\tPIAIC123456\n",
    "21:41:56 From Arif Najmi to Everyone:\n",
    "\t125657\n",
    "21:42:00 From Rehan Baig - PIAIC73919 to Everyone:\n",
    "\tPIAIC73919\n",
    "21:42:00 From STONE to Everyone:\n",
    "\tZAM - 786\n",
    "21:42:01 From M. Waheed Iqbal (PIAIC_126369) to Everyone:\n",
    "\tPIAIC_126369\n",
    "21:42:03 From . to Everyone:\n",
    "\tPIAIC210905\n",
    "21:42:06 From ABDUL KHALIQ to Everyone:\n",
    "\tPIAIC-604031\n",
    "21:42:11 From Arshad Siddiqui to Everyone:\n",
    "\tPIAIC120702\n",
    "21:42:13 From Ali Zar FSD to Everyone:\n",
    "\tPIaic 223972\n",
    "21:42:13 From Azfar Suhail to Everyone:\n",
    "\tPIAIC218333\n",
    "21:42:14 From Kamran Ahmed to Everyone:\n",
    "\tPIAIC139495\n",
    "21:42:18 From Ahmed to Everyone:\n",
    "\t216511\n",
    "21:42:20 From Ayesha Arshad to Everyone:\n",
    "\tPIAIC-225620\n",
    "21:42:25 From Kamal Hassan to Everyone:\n",
    "\tPIAIC58320\n",
    "21:42:29 From Ahmed to Everyone:\n",
    "\tPIAIC-2165111\n",
    "21:42:30 From Kaleem to Everyone:\n",
    "\tPIAIC:001100\n",
    "21:42:34 From Arif Najmi to Everyone:\n",
    "\tPIAIC 125657\n",
    "21:42:35 From Yasir to Everyone:\n",
    "\tPIAIC63502\n",
    "21:42:37 From Ahmed to Everyone:\n",
    "\tPIAIC-216511\n",
    "21:42:41 From Ali to Everyone:\n",
    "\tPIAIC76588\n",
    "21:42:46 From M Qasim to Everyone:\n",
    "\tPIAIC178397\n",
    "21:42:55 From Dr. Ghulam Shabbir to Everyone:\n",
    "\tPIAIC208889\n",
    "21:42:59 From IMRAN to Everyone:\n",
    "\tPIAIC216423\n",
    "21:43:04 From PIAIC80919 Muhammad Asad to Qasim(CGAIO)(Direct Message):\n",
    "\tPIAIC80919\n",
    "21:43:04 From Ahmed to Everyone:\n",
    "\tPIAIC-216511\n",
    "21:43:16 From Kamal Hassan to Everyone:\n",
    "\tPIAIC,58321\n",
    "21:43:29 From Zeeshan Abbas to Everyone:\n",
    "\tPIAIC221479\n",
    "21:43:43 From Amanat Wattoo to Everyone:\n",
    "\tPIAIC174651\n",
    "21:44:12 From Ahsan to Everyone:\n",
    "\tPIAIC185091\n",
    "21:44:26 From Amanat Wattoo to Everyone:\n",
    "\t@Ikhlas Bhojani bhai chat ko save kaisy save krwia h\n",
    "21:45:09 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani bhai...\"\n",
    "\t\n",
    "\tneeche three dot se\n",
    "21:46:20 From Ikhlas Bhojani to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani bhai...\"\n",
    "\t\n",
    "\tJahan msg likhte hen uske neeche three dot he\n",
    "21:46:30 From Amanat Wattoo to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani bhai...\"\n",
    "\t\n",
    "\tok find thanks\n",
    "21:47:27 From Amanat Wattoo to Everyone:\n",
    "\tReplying to \"@Ikhlas Bhojani bhai...\"\n",
    "\t\n",
    "\tfound\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re \n",
    "\n",
    "pattren = r'''\n",
    "(\\d{2}:\\d{2}:\\d{2}) From (.*) to Everyone:\n",
    "\t(PIAIC-? ?\\d{5,6})\n",
    "'''\n",
    "\n",
    "checking = re.findall(pattren,x)\n",
    "\n",
    "display(checking)\n",
    "# checking\n",
    "df : pd.DataFrame = pd.DataFrame(checking,columns=['Time','Name','Roll No'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(3, 8), match='class'>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r'\\bclass\\b')\n",
    "print(p.search('no class at all'))\n",
    "print(p.search('the declassified algorithm'))\n",
    "print(p.search('one subclass is'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the the'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example, the following RE detects doubled words in a string.\n",
    "p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n",
    "p.search('Paris in the the spring').group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaError",
     "evalue": "column 'column1' not in dataframe. Columns in dataframe: ['foo', 'baz']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m simple_schema \u001b[38;5;241m=\u001b[39m DataFrameSchema({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn1\u001b[39m\u001b[38;5;124m\"\u001b[39m: Column(\n\u001b[0;32m      4\u001b[0m         Int, Check(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, element_wise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m                    error\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrange checker [0, 10]\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m })\n\u001b[0;32m      8\u001b[0m wrong_column_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      9\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoo\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     10\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaz\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     11\u001b[0m })\n\u001b[1;32m---> 13\u001b[0m simple_schema\u001b[38;5;241m.\u001b[39mvalidate(wrong_column_df)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandera\\api\\pandas\\container.py:125\u001b[0m, in \u001b[0;36mDataFrameSchema.validate\u001b[1;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[0;32m    113\u001b[0m     check_obj \u001b[38;5;241m=\u001b[39m check_obj\u001b[38;5;241m.\u001b[39mmap_partitions(  \u001b[38;5;66;03m# type: ignore [operator]\u001b[39;00m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate,\n\u001b[0;32m    115\u001b[0m         head\u001b[38;5;241m=\u001b[39mhead,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m         meta\u001b[38;5;241m=\u001b[39mcheck_obj,\n\u001b[0;32m    122\u001b[0m     )\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_obj\u001b[38;5;241m.\u001b[39mpandera\u001b[38;5;241m.\u001b[39madd_schema(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(\n\u001b[0;32m    126\u001b[0m     check_obj\u001b[38;5;241m=\u001b[39mcheck_obj,\n\u001b[0;32m    127\u001b[0m     head\u001b[38;5;241m=\u001b[39mhead,\n\u001b[0;32m    128\u001b[0m     tail\u001b[38;5;241m=\u001b[39mtail,\n\u001b[0;32m    129\u001b[0m     sample\u001b[38;5;241m=\u001b[39msample,\n\u001b[0;32m    130\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m    131\u001b[0m     lazy\u001b[38;5;241m=\u001b[39mlazy,\n\u001b[0;32m    132\u001b[0m     inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m    133\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandera\\api\\pandas\\container.py:154\u001b[0m, in \u001b[0;36mDataFrameSchema._validate\u001b[1;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_inferred:\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is an inferred schema that hasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt been \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodified. It\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended that you refine the schema \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    152\u001b[0m     )\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_backend(check_obj)\u001b[38;5;241m.\u001b[39mvalidate(\n\u001b[0;32m    155\u001b[0m     check_obj,\n\u001b[0;32m    156\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    157\u001b[0m     head\u001b[38;5;241m=\u001b[39mhead,\n\u001b[0;32m    158\u001b[0m     tail\u001b[38;5;241m=\u001b[39mtail,\n\u001b[0;32m    159\u001b[0m     sample\u001b[38;5;241m=\u001b[39msample,\n\u001b[0;32m    160\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m    161\u001b[0m     lazy\u001b[38;5;241m=\u001b[39mlazy,\n\u001b[0;32m    162\u001b[0m     inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m    163\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:104\u001b[0m, in \u001b[0;36mDataFrameSchemaBackend.validate\u001b[1;34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[0;32m     99\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_schema_components(\n\u001b[0;32m    100\u001b[0m     check_obj, schema, column_info\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# run the checks\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m error_handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_checks_and_handle_errors(\n\u001b[0;32m    105\u001b[0m     error_handler,\n\u001b[0;32m    106\u001b[0m     schema,\n\u001b[0;32m    107\u001b[0m     check_obj,\n\u001b[0;32m    108\u001b[0m     column_info,\n\u001b[0;32m    109\u001b[0m     sample,\n\u001b[0;32m    110\u001b[0m     components,\n\u001b[0;32m    111\u001b[0m     lazy,\n\u001b[0;32m    112\u001b[0m     head,\n\u001b[0;32m    113\u001b[0m     tail,\n\u001b[0;32m    114\u001b[0m     random_state,\n\u001b[0;32m    115\u001b[0m )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_handler\u001b[38;5;241m.\u001b[39mcollected_errors:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_invalid_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:179\u001b[0m, in \u001b[0;36mDataFrameSchemaBackend.run_checks_and_handle_errors\u001b[1;34m(self, error_handler, schema, check_obj, column_info, sample, components, lazy, head, tail, random_state)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m             error \u001b[38;5;241m=\u001b[39m SchemaError(\n\u001b[0;32m    170\u001b[0m                 schema,\n\u001b[0;32m    171\u001b[0m                 data\u001b[38;5;241m=\u001b[39mcheck_obj,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m                 reason_code\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mreason_code,\n\u001b[0;32m    178\u001b[0m             )\n\u001b[1;32m--> 179\u001b[0m         error_handler\u001b[38;5;241m.\u001b[39mcollect_error(\n\u001b[0;32m    180\u001b[0m             validation_type(result\u001b[38;5;241m.\u001b[39mreason_code),\n\u001b[0;32m    181\u001b[0m             result\u001b[38;5;241m.\u001b[39mreason_code,\n\u001b[0;32m    182\u001b[0m             error,\n\u001b[0;32m    183\u001b[0m             result\u001b[38;5;241m.\u001b[39moriginal_exc,\n\u001b[0;32m    184\u001b[0m         )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_handler\n",
      "File \u001b[1;32md:\\anaconda\\envs\\'py-11'\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[0m, in \u001b[0;36mErrorHandler.collect_error\u001b[1;34m(self, error_type, reason_code, schema_error, original_exc)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m:param error_type: type of error\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moriginal_exc\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mSchemaError\u001b[0m: column 'column1' not in dataframe. Columns in dataframe: ['foo', 'baz']"
     ]
    }
   ],
   "source": [
    "from pandera import DataFrameSchema,Column,Check,Int\n",
    "simple_schema = DataFrameSchema({\n",
    "    \"column1\": Column(\n",
    "        Int, Check(lambda x: 0 <= x <= 10, element_wise=True,\n",
    "                   error=\"range checker [0, 10]\"))\n",
    "})\n",
    "\n",
    "wrong_column_df = pd.DataFrame({\n",
    "   \"foo\": [\"bar\"] * 10,\n",
    "   \"baz\": [1] * 10\n",
    "})\n",
    "\n",
    "simple_schema.validate(wrong_column_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
